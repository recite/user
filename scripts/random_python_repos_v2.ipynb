{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8318b041-358b-4ebf-929c-f458a54cf685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 10 random hours from GHArchive over the past 10 years\n",
      "Will select up to 10 repositories per hour\n",
      "\n",
      "Sample 1/10: 2018-09-05, hour 11\n",
      "URL: https://data.gharchive.org/2018-09-05-11.json.gz\n",
      "Downloading file...\n",
      "Sampling repositories...\n",
      "Found 10 repositories\n",
      "Deleted temporary file\n",
      "\n",
      "Sample 2/10: 2022-02-23, hour 8\n",
      "URL: https://data.gharchive.org/2022-02-23-8.json.gz\n",
      "Downloading file...\n",
      "Sampling repositories...\n",
      "Found 10 repositories\n",
      "Deleted temporary file\n",
      "\n",
      "Sample 3/10: 2025-02-02, hour 2\n",
      "URL: https://data.gharchive.org/2025-02-02-2.json.gz\n",
      "Downloading file...\n",
      "Sampling repositories...\n",
      "Found 10 repositories\n",
      "Deleted temporary file\n",
      "\n",
      "Sample 4/10: 2020-07-22, hour 2\n",
      "URL: https://data.gharchive.org/2020-07-22-2.json.gz\n",
      "Downloading file...\n",
      "Sampling repositories...\n",
      "Found 10 repositories\n",
      "Deleted temporary file\n",
      "\n",
      "Sample 5/10: 2023-02-19, hour 9\n",
      "URL: https://data.gharchive.org/2023-02-19-9.json.gz\n",
      "Downloading file...\n",
      "Sampling repositories...\n",
      "Found 10 repositories\n",
      "Deleted temporary file\n",
      "\n",
      "Sample 6/10: 2019-08-11, hour 0\n",
      "URL: https://data.gharchive.org/2019-08-11-0.json.gz\n",
      "Downloading file...\n",
      "Sampling repositories...\n",
      "Found 10 repositories\n",
      "Deleted temporary file\n",
      "\n",
      "Sample 7/10: 2020-04-29, hour 4\n",
      "URL: https://data.gharchive.org/2020-04-29-4.json.gz\n",
      "Downloading file...\n",
      "Sampling repositories...\n",
      "Found 10 repositories\n",
      "Deleted temporary file\n",
      "\n",
      "Sample 8/10: 2024-06-14, hour 15\n",
      "URL: https://data.gharchive.org/2024-06-14-15.json.gz\n",
      "Downloading file...\n",
      "Sampling repositories...\n",
      "Found 10 repositories\n",
      "Deleted temporary file\n",
      "\n",
      "Sample 9/10: 2016-10-15, hour 21\n",
      "URL: https://data.gharchive.org/2016-10-15-21.json.gz\n",
      "Downloading file...\n",
      "Sampling repositories...\n",
      "Found 10 repositories\n",
      "Deleted temporary file\n",
      "\n",
      "Sample 10/10: 2020-09-19, hour 13\n",
      "URL: https://data.gharchive.org/2020-09-19-13.json.gz\n",
      "Downloading file...\n",
      "Sampling repositories...\n",
      "Found 10 repositories\n",
      "Deleted temporary file\n",
      "\n",
      "Sampled a total of 100 repositories\n",
      "Created DataFrame with shape (100, 6)\n",
      "\n",
      "Checking language for each repository...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493e346a54044e8dbb27705af88f09b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository macjohnny/openapi-generator-1 not found\n",
      "Repository Dborkowski/SecondHandCars4You not found\n",
      "Repository Logicye/CyberXSecurity-Project-1 not found\n",
      "Repository ukyohpq/PythonMLB not found\n",
      "Repository NeofetchNpc/update-repo not found\n",
      "Error checking Micraow/AutoApiSecret: 403\n",
      "Repository MatthewTe/velkoz-data-warehouse-application not found\n",
      "Repository ratnasute/ratnasute.github.io not found\n",
      "Repository robced/onibot not found\n",
      "Repository 01PhiHung01/LAB2_CNTT2 not found\n",
      "Repository zsxs2/zs not found\n",
      "Repository Madogiwa0124/dogfeeds not found\n",
      "Repository Eduardo-Gonz/todo-app not found\n",
      "Repository dmnapolitano/tate_lang not found\n",
      "Repository yuhaocan/Flutter_Clock not found\n",
      "Repository adsviewer/turboviewer not found\n",
      "Repository daisuke721/yasai_pocket not found\n",
      "Repository zootyducky/KU2024_CGIP_FABRIK_WEB_DEMO not found\n",
      "Repository atomist-test-web/project_hwnxspjlsrl0m not found\n",
      "Repository chronos280/Fork-me not found\n",
      "Repository sust-code/json-pretty-printer-flta not found\n",
      "Repository obryantphotography/obryantphotography.github.io not found\n",
      "Repository UnclearMist/UnclearMist.github.io not found\n",
      "Repository lias213/helloworld not found\n",
      "Repository yinjikai/yinjikai not found\n",
      "Repository hai298/helloworld not found\n",
      "Repository widewise/mslearn-tailspin-spacegame-web not found\n",
      "Got language information for 73 repositories\n",
      "Found 4 Python repositories\n",
      "\n",
      "Saved 4 Python repositories to python_repos_from_gharchive.jsonl\n",
      "\n",
      "Sample of Python repositories found:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stars</th>\n",
       "      <th>language</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spreaker/prometheus-pgbouncer-exporter</td>\n",
       "      <td>107</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/spreaker/prometheus-pgbounc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>thp/urlwatch</td>\n",
       "      <td>2891</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/thp/urlwatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ZhouZ-1/github-stats</td>\n",
       "      <td>3</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/ZhouZ-1/github-stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MatthewNavy/MinimaxAB</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/MatthewNavy/MinimaxAB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name  stars language  \\\n",
       "0   spreaker/prometheus-pgbouncer-exporter    107   Python   \n",
       "8                             thp/urlwatch   2891   Python   \n",
       "24                    ZhouZ-1/github-stats      3   Python   \n",
       "48                   MatthewNavy/MinimaxAB      0   Python   \n",
       "\n",
       "                                                  url  \n",
       "0   https://github.com/spreaker/prometheus-pgbounc...  \n",
       "8                     https://github.com/thp/urlwatch  \n",
       "24            https://github.com/ZhouZ-1/github-stats  \n",
       "48           https://github.com/MatthewNavy/MinimaxAB  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Also saved results to python_repos_from_gharchive.csv\n"
     ]
    }
   ],
   "source": [
    "# Random Python Repository Sampler using GHArchive\n",
    "#\n",
    "# This notebook implements a method to get random Python repositories from GitHub\n",
    "# by sampling random hours from GHArchive data over the past several years.\n",
    "\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import gzip\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# Configuration parameters\n",
    "n_samples = 10  # Number of hour samples to take\n",
    "years_back = 10  # How many years back to sample from\n",
    "n_repos_per_hour = 10  # Number of repositories to sample per hour\n",
    "\n",
    "# Create temp directory for downloads\n",
    "os.makedirs(\"temp\", exist_ok=True)\n",
    "\n",
    "# Function to pick a random hour over the last Y years\n",
    "def get_random_hour(years_back=10):\n",
    "    \"\"\"\n",
    "    Generate a random date and hour within the specified number of years back.\n",
    "    \n",
    "    Args:\n",
    "        years_back: Number of years to look back\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (date_str, hour)\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    start_date = now - timedelta(days=365 * years_back)\n",
    "    \n",
    "    # Random number of days between start_date and now\n",
    "    days_range = (now - start_date).days\n",
    "    random_days = random.randint(0, days_range)\n",
    "    \n",
    "    # Generate the random date\n",
    "    random_date = start_date + timedelta(days=random_days)\n",
    "    date_str = random_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Random hour (0-23)\n",
    "    hour = random.randint(0, 23)\n",
    "    \n",
    "    return date_str, hour\n",
    "\n",
    "# Function to get GHArchive URL for a specific date and hour\n",
    "def get_gharchive_url(date_str, hour):\n",
    "    \"\"\"Generate the URL for a GHArchive file\"\"\"\n",
    "    return f\"https://data.gharchive.org/{date_str}-{hour}.json.gz\"\n",
    "\n",
    "# Function to download a GHArchive file\n",
    "def download_gharchive_file(url, save_path):\n",
    "    \"\"\"\n",
    "    Download a GHArchive file\n",
    "    \n",
    "    Args:\n",
    "        url: URL to download\n",
    "        save_path: Where to save the file\n",
    "        \n",
    "    Returns:\n",
    "        Path to the downloaded file or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with open(save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "                \n",
    "        return save_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to sample repositories from a GHArchive file\n",
    "def sample_repos_from_file(file_path, n_repos=10):\n",
    "    \"\"\"\n",
    "    Sample random repositories from a GHArchive file\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the GHArchive file\n",
    "        n_repos: Number of repositories to sample\n",
    "        \n",
    "    Returns:\n",
    "        List of repository dictionaries\n",
    "    \"\"\"\n",
    "    repos = []\n",
    "    seen_repos = set()\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "            # Read the file line by line\n",
    "            for line in f:\n",
    "                try:\n",
    "                    event = json.loads(line)\n",
    "                    \n",
    "                    # Extract repository information if present\n",
    "                    if 'repo' in event and 'name' in event['repo']:\n",
    "                        repo_name = event['repo']['name']\n",
    "                        \n",
    "                        # Skip if we've already seen this repo\n",
    "                        if repo_name in seen_repos:\n",
    "                            continue\n",
    "                            \n",
    "                        seen_repos.add(repo_name)\n",
    "                        \n",
    "                        repos.append({\n",
    "                            'name': repo_name,\n",
    "                            'url': f\"https://github.com/{repo_name}\",\n",
    "                            'event_type': event.get('type', 'Unknown'),\n",
    "                            'timestamp': event.get('created_at', '')\n",
    "                        })\n",
    "                        \n",
    "                        # If we have enough repos, stop\n",
    "                        if len(repos) >= n_repos:\n",
    "                            break\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "    \n",
    "    # If we have more repos than needed, take a random sample\n",
    "    if len(repos) > n_repos:\n",
    "        repos = random.sample(repos, n_repos)\n",
    "        \n",
    "    return repos\n",
    "\n",
    "# Function to check if a repository uses Python\n",
    "def check_repo_language(repo_name):\n",
    "    \"\"\"\n",
    "    Check if a repository uses Python as its main language\n",
    "    \n",
    "    Args:\n",
    "        repo_name: Repository name (owner/repo)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with repository information or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        api_url = f\"https://api.github.com/repos/{repo_name}\"\n",
    "        response = requests.get(api_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            repo_data = response.json()\n",
    "            \n",
    "            return {\n",
    "                'name': repo_name,\n",
    "                'url': f\"https://github.com/{repo_name}\",\n",
    "                'language': repo_data.get('language'),\n",
    "                'stars': repo_data.get('stargazers_count', 0),\n",
    "                'forks': repo_data.get('forks_count', 0),\n",
    "                'created_at': repo_data.get('created_at', ''),\n",
    "                'updated_at': repo_data.get('updated_at', ''),\n",
    "                'is_python': repo_data.get('language') == 'Python'\n",
    "            }\n",
    "        elif response.status_code == 404:\n",
    "            print(f\"Repository {repo_name} not found\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"Error checking {repo_name}: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Exception checking {repo_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "print(f\"Sampling {n_samples} random hours from GHArchive over the past {years_back} years\")\n",
    "print(f\"Will select up to {n_repos_per_hour} repositories per hour\")\n",
    "\n",
    "# Store all sampled repositories\n",
    "all_repos = []\n",
    "\n",
    "# Sample multiple random hours\n",
    "for i in range(n_samples):\n",
    "    # Get random date and hour\n",
    "    date_str, hour = get_random_hour(years_back)\n",
    "    print(f\"\\nSample {i+1}/{n_samples}: {date_str}, hour {hour}\")\n",
    "    \n",
    "    # Construct URL\n",
    "    url = get_gharchive_url(date_str, hour)\n",
    "    print(f\"URL: {url}\")\n",
    "    \n",
    "    # Create filename for the downloaded file\n",
    "    filename = f\"gharchive_{date_str}_{hour}.json.gz\"\n",
    "    file_path = os.path.join(\"temp\", filename)\n",
    "    \n",
    "    # Download the file\n",
    "    print(f\"Downloading file...\")\n",
    "    downloaded_file = download_gharchive_file(url, file_path)\n",
    "    \n",
    "    if downloaded_file:\n",
    "        # Sample repositories from the file\n",
    "        print(f\"Sampling repositories...\")\n",
    "        repos = sample_repos_from_file(downloaded_file, n_repos_per_hour)\n",
    "        print(f\"Found {len(repos)} repositories\")\n",
    "        \n",
    "        # Add sample info to each repo\n",
    "        for repo in repos:\n",
    "            repo['sample_date'] = date_str\n",
    "            repo['sample_hour'] = hour\n",
    "        \n",
    "        all_repos.extend(repos)\n",
    "        \n",
    "        # Delete the file to save space\n",
    "        os.remove(downloaded_file)\n",
    "        print(f\"Deleted temporary file\")\n",
    "    else:\n",
    "        print(f\"Failed to download file for {date_str}, hour {hour}\")\n",
    "\n",
    "print(f\"\\nSampled a total of {len(all_repos)} repositories\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "repos_df = pd.DataFrame(all_repos)\n",
    "print(f\"Created DataFrame with shape {repos_df.shape}\")\n",
    "\n",
    "# Check language for each repository\n",
    "print(\"\\nChecking language for each repository...\")\n",
    "language_info = []\n",
    "\n",
    "for i, repo in enumerate(tqdm(repos_df.itertuples(), total=len(repos_df))):\n",
    "    # Add a small delay to avoid rate limiting\n",
    "    if i > 0 and i % 10 == 0:\n",
    "        time.sleep(2)\n",
    "        \n",
    "    info = check_repo_language(repo.name)\n",
    "    if info:\n",
    "        language_info.append(info)\n",
    "\n",
    "# Convert language info to DataFrame\n",
    "language_df = pd.DataFrame(language_info)\n",
    "print(f\"Got language information for {len(language_df)} repositories\")\n",
    "\n",
    "# Filter for Python repositories\n",
    "python_repos = language_df[language_df['is_python'] == True].copy()\n",
    "print(f\"Found {len(python_repos)} Python repositories\")\n",
    "\n",
    "# Save to JSONL\n",
    "output_file = \"python_repos_from_gharchive.jsonl\"\n",
    "with open(output_file, 'w') as f:\n",
    "    for _, repo in python_repos.iterrows():\n",
    "        f.write(json.dumps(repo.to_dict()) + '\\n')\n",
    "\n",
    "print(f\"\\nSaved {len(python_repos)} Python repositories to {output_file}\")\n",
    "\n",
    "# Display sample of Python repositories\n",
    "print(\"\\nSample of Python repositories found:\")\n",
    "display(python_repos[['name', 'stars', 'language', 'url']].head(10))\n",
    "\n",
    "# Optional: Create a CSV version too\n",
    "python_repos.to_csv(\"python_repos_from_gharchive.csv\", index=False)\n",
    "print(f\"Also saved results to python_repos_from_gharchive.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581764ce-58dc-41a1-9940-72fe96616215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting random Python repository sampling...\n",
      "GitHub API Search Rate Limit: 30/30\n",
      "Rate limit resets at: 2025-03-24 14:49:28\n",
      "\n",
      "Sampling from 10 random hours across 10 years:\n",
      "  1. 2017-02-13 09:00\n",
      "  2. 2019-05-02 19:00\n",
      "  3. 2019-12-21 08:00\n",
      "  4. 2020-07-17 04:00\n",
      "  5. 2021-04-29 15:00\n",
      "  6. 2021-10-04 01:00\n",
      "  7. 2021-12-31 11:00\n",
      "  8. 2024-09-14 17:00\n",
      "  9. 2024-10-29 09:00\n",
      "  10. 2025-03-24 04:00\n",
      "\n",
      "Fetching up to 10 Python repositories from each hour:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69decf8c887447cebb1108050e4ff99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 Python repositories for 2017-02-13 09:00\n",
      "Found 10 Python repositories for 2019-05-02 19:00\n",
      "Found 10 Python repositories for 2019-12-21 08:00\n",
      "Found 10 Python repositories for 2020-07-17 04:00\n",
      "Found 10 Python repositories for 2021-04-29 15:00\n",
      "Found 10 Python repositories for 2021-10-04 01:00\n",
      "Found 10 Python repositories for 2021-12-31 11:00\n",
      "Found 10 Python repositories for 2024-09-14 17:00\n",
      "Found 10 Python repositories for 2024-10-29 09:00\n",
      "Found 10 Python repositories for 2025-03-24 04:00\n",
      "\n",
      "Found 100 Python repositories in total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Sample of Python Repositories</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stars</th>\n",
       "      <th>language</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hideki-saito/FSA</td>\n",
       "      <td>3</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/hideki-saito/FSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AKor03/test_task</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/AKor03/test_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ace12358/WordBreaker</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/ace12358/WordBreaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yhgnice/webonline</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/yhgnice/webonline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>freshpie/python</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/freshpie/python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lawrenceleejr/PlottingTools</td>\n",
       "      <td>2</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/lawrenceleejr/PlottingTools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gtomek123/deckrep</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/gtomek123/deckrep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NotiflyDev/Python</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/NotiflyDev/Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>runt18/poseidon</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/runt18/poseidon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>calvinYe/my_dj18study</td>\n",
       "      <td>0</td>\n",
       "      <td>Python</td>\n",
       "      <td>https://github.com/calvinYe/my_dj18study</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  stars language  \\\n",
       "0             hideki-saito/FSA      3   Python   \n",
       "1             AKor03/test_task      0   Python   \n",
       "2         ace12358/WordBreaker      0   Python   \n",
       "3            yhgnice/webonline      0   Python   \n",
       "4              freshpie/python      0   Python   \n",
       "5  lawrenceleejr/PlottingTools      2   Python   \n",
       "6            gtomek123/deckrep      0   Python   \n",
       "7            NotiflyDev/Python      0   Python   \n",
       "8              runt18/poseidon      0   Python   \n",
       "9        calvinYe/my_dj18study      0   Python   \n",
       "\n",
       "                                              url  \n",
       "0             https://github.com/hideki-saito/FSA  \n",
       "1             https://github.com/AKor03/test_task  \n",
       "2         https://github.com/ace12358/WordBreaker  \n",
       "3            https://github.com/yhgnice/webonline  \n",
       "4              https://github.com/freshpie/python  \n",
       "5  https://github.com/lawrenceleejr/PlottingTools  \n",
       "6            https://github.com/gtomek123/deckrep  \n",
       "7            https://github.com/NotiflyDev/Python  \n",
       "8              https://github.com/runt18/poseidon  \n",
       "9        https://github.com/calvinYe/my_dj18study  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 100 repositories to python_repos_sample.jsonl\n",
      "Also saved to python_repos_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# Random Python Repository Sampling via GitHub API\n",
    "#\n",
    "# This notebook implements a method to get random Python repositories from GitHub\n",
    "# by sampling random hours across the past decade.\n",
    "\n",
    "import requests\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Configuration parameters\n",
    "N_SAMPLES = 10  # Number of random hours to sample\n",
    "REPOS_PER_HOUR = 10  # Number of repositories to fetch per hour\n",
    "YEARS_BACK = 10  # How many years back to sample from\n",
    "OUTPUT_FILE = \"python_repos_sample.jsonl\"  # Where to save the results\n",
    "\n",
    "# Optional: GitHub API token (set this to avoid rate limits)\n",
    "# To use this, create a .env file with GITHUB_TOKEN=your_token_here\n",
    "# or export GITHUB_TOKEN as an environment variable\n",
    "github_token = \"\" #os.environ.get(\"GITHUB_TOKEN\", \"\")\n",
    "\n",
    "# Function to generate a random date and hour from the past X years\n",
    "def get_random_date_hour(years_back=10):\n",
    "    \"\"\"Generate a random date and hour from the past X years\"\"\"\n",
    "    now = datetime.now()\n",
    "    start_date = now - timedelta(days=365 * years_back)\n",
    "    random_days = random.randint(0, (now - start_date).days)\n",
    "    random_date = start_date + timedelta(days=random_days)\n",
    "    random_hour = random.randint(0, 23)\n",
    "    \n",
    "    return random_date.replace(hour=random_hour, minute=0, second=0, microsecond=0)\n",
    "\n",
    "# Function to get repositories updated in a specific hour\n",
    "def get_repos_from_hour(date_hour, language=\"Python\", per_page=10, token=\"\"):\n",
    "    \"\"\"\n",
    "    Get repositories updated in a specific hour\n",
    "    \n",
    "    Args:\n",
    "        date_hour: Datetime object representing the hour to sample\n",
    "        language: Programming language to filter for\n",
    "        per_page: Maximum number of repositories to return\n",
    "        token: GitHub API token (optional)\n",
    "        \n",
    "    Returns:\n",
    "        List of repository dictionaries\n",
    "    \"\"\"\n",
    "    # Format timestamps for GitHub Search API\n",
    "    start_time = date_hour.isoformat() + \"Z\"  # GitHub needs the Z suffix for UTC\n",
    "    end_time = (date_hour + timedelta(hours=1)).isoformat() + \"Z\"\n",
    "    \n",
    "    # Construct GitHub Search API query\n",
    "    query = f\"language:{language} pushed:{start_time}..{end_time}\"\n",
    "    \n",
    "    # Prepare request headers\n",
    "    headers = {\"Accept\": \"application/vnd.github.v3+json\"}\n",
    "    if token:\n",
    "        headers[\"Authorization\"] = f\"token {token}\"\n",
    "    \n",
    "    # Make API request\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            \"https://api.github.com/search/repositories\",\n",
    "            params={\n",
    "                \"q\": query,\n",
    "                \"sort\": \"updated\",\n",
    "                \"order\": \"desc\",\n",
    "                \"per_page\": per_page\n",
    "            },\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        response.raise_for_status()  # Raise exception for 4XX/5XX responses\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Check if we got any results\n",
    "        if \"items\" in data:\n",
    "            repos = data[\"items\"]\n",
    "            \n",
    "            # Extract relevant fields to keep data size manageable\n",
    "            cleaned_repos = []\n",
    "            for repo in repos:\n",
    "                cleaned_repos.append({\n",
    "                    \"name\": repo.get(\"full_name\"),\n",
    "                    \"url\": repo.get(\"html_url\"),\n",
    "                    \"description\": repo.get(\"description\"),\n",
    "                    \"language\": repo.get(\"language\"),\n",
    "                    \"stars\": repo.get(\"stargazers_count\", 0),\n",
    "                    \"forks\": repo.get(\"forks_count\", 0),\n",
    "                    \"created_at\": repo.get(\"created_at\"),\n",
    "                    \"updated_at\": repo.get(\"updated_at\"),\n",
    "                    \"sample_datetime\": start_time\n",
    "                })\n",
    "            \n",
    "            return cleaned_repos\n",
    "        else:\n",
    "            print(f\"No results found for {start_time}\")\n",
    "            return []\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error querying GitHub API: {e}\")\n",
    "        \n",
    "        # Check for rate limiting\n",
    "        if response.status_code == 403 and \"rate limit exceeded\" in response.text.lower():\n",
    "            reset_time = int(response.headers.get(\"X-RateLimit-Reset\", 0))\n",
    "            current_time = int(time.time())\n",
    "            wait_time = max(reset_time - current_time, 0)\n",
    "            \n",
    "            print(f\"Rate limit exceeded. Resets in {wait_time} seconds\")\n",
    "            \n",
    "            # If wait time is reasonable, wait and retry\n",
    "            if wait_time < 300:  # 5 minutes max wait\n",
    "                print(f\"Waiting {wait_time} seconds to retry...\")\n",
    "                time.sleep(wait_time + 1)\n",
    "                return get_repos_from_hour(date_hour, language, per_page, token)\n",
    "        \n",
    "        return []\n",
    "\n",
    "# Check GitHub API rate limits\n",
    "def check_rate_limits(token=\"\"):\n",
    "    \"\"\"Check current GitHub API rate limits\"\"\"\n",
    "    headers = {}\n",
    "    if token:\n",
    "        headers[\"Authorization\"] = f\"token {token}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\n",
    "            \"https://api.github.com/rate_limit\",\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            search_limit = data.get(\"resources\", {}).get(\"search\", {})\n",
    "            \n",
    "            remaining = search_limit.get(\"remaining\", 0)\n",
    "            limit = search_limit.get(\"limit\", 0)\n",
    "            reset_time = search_limit.get(\"reset\", 0)\n",
    "            \n",
    "            reset_datetime = datetime.fromtimestamp(reset_time)\n",
    "            \n",
    "            print(f\"GitHub API Search Rate Limit: {remaining}/{limit}\")\n",
    "            print(f\"Rate limit resets at: {reset_datetime}\")\n",
    "            \n",
    "            return remaining\n",
    "        else:\n",
    "            print(f\"Error checking rate limits: {response.status_code}\")\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking rate limits: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Main function to sample repositories\n",
    "def sample_random_python_repos(n_samples=10, repos_per_hour=10, years_back=10, token=\"\"):\n",
    "    \"\"\"\n",
    "    Sample random Python repositories by randomly selecting hours\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of random hours to sample\n",
    "        repos_per_hour: Number of repositories to fetch per hour\n",
    "        years_back: How many years back to sample from\n",
    "        token: GitHub API token (optional)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame of sampled repositories\n",
    "    \"\"\"\n",
    "    # Check rate limits first\n",
    "    remaining_calls = check_rate_limits(token)\n",
    "    if remaining_calls < n_samples:\n",
    "        print(f\"Warning: You only have {remaining_calls} API calls remaining, but requesting {n_samples} samples\")\n",
    "        print(\"Consider using a GitHub token or reducing n_samples\")\n",
    "    \n",
    "    # Generate random hours\n",
    "    random_hours = [get_random_date_hour(years_back) for _ in range(n_samples)]\n",
    "    random_hours.sort()  # Sort chronologically for nicer output\n",
    "    \n",
    "    print(f\"\\nSampling from {n_samples} random hours across {years_back} years:\")\n",
    "    for i, hour in enumerate(random_hours):\n",
    "        print(f\"  {i+1}. {hour.strftime('%Y-%m-%d %H:00')}\")\n",
    "    \n",
    "    # Sample repositories from each random hour\n",
    "    all_repos = []\n",
    "    \n",
    "    print(f\"\\nFetching up to {repos_per_hour} Python repositories from each hour:\")\n",
    "    for hour in tqdm(random_hours):\n",
    "        # Format for display\n",
    "        hour_str = hour.strftime(\"%Y-%m-%d %H:00\")\n",
    "        \n",
    "        # Get repositories for this hour\n",
    "        repos = get_repos_from_hour(hour, \"Python\", repos_per_hour, token)\n",
    "        \n",
    "        if repos:\n",
    "            print(f\"Found {len(repos)} Python repositories for {hour_str}\")\n",
    "            all_repos.extend(repos)\n",
    "        else:\n",
    "            print(f\"No repositories found for {hour_str}\")\n",
    "        \n",
    "        # Add a small delay to avoid hitting rate limits\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_repos)\n",
    "    \n",
    "    # Return the DataFrame\n",
    "    return df\n",
    "\n",
    "# Run the sampling\n",
    "print(\"Starting random Python repository sampling...\")\n",
    "repos_df = sample_random_python_repos(\n",
    "    n_samples=N_SAMPLES,\n",
    "    repos_per_hour=REPOS_PER_HOUR,\n",
    "    years_back=YEARS_BACK,\n",
    "    token=github_token\n",
    ")\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nFound {len(repos_df)} Python repositories in total\")\n",
    "\n",
    "# Display sample of repositories\n",
    "display(HTML(\"<h3>Sample of Python Repositories</h3>\"))\n",
    "if len(repos_df) > 0:\n",
    "    display(repos_df[['name', 'stars', 'language', 'url']].head(10))\n",
    "else:\n",
    "    print(\"No repositories found.\")\n",
    "\n",
    "# Save to JSONL file\n",
    "if len(repos_df) > 0:\n",
    "    repos_df.to_json(OUTPUT_FILE, orient='records', lines=True)\n",
    "    print(f\"\\nSaved {len(repos_df)} repositories to {OUTPUT_FILE}\")\n",
    "\n",
    "    # Also save a CSV for easier viewing\n",
    "    csv_file = OUTPUT_FILE.replace('.jsonl', '.csv')\n",
    "    repos_df.to_csv(csv_file, index=False)\n",
    "    print(f\"Also saved to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e2ab4-6c3e-432e-8614-898a1c3e1149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Data Science)",
   "language": "python",
   "name": "py311ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
