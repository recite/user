{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f43cc917-67d1-4afd-8264-0f75794b1593",
   "metadata": {},
   "source": [
    "### Which Python Packages are Included?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84e5f1c-0f18-4dae-85ec-8e0abea6c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import random\n",
    "import os\n",
    "import logging\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import tempfile\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from typing import Set, List, Tuple, Dict, Any, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d2341e-35fb-454e-b0ba-148e4bf171e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"repo_analysis.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9014b715-9fb2-4ee1-b136-1f467bf562d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "GITHUB_API_URL = \"https://api.github.com\"\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\"\n",
    "]\n",
    "GITHUB_TOKEN = \"\"\n",
    "#os.environ.get(\"GITHUB_TOKEN\")\n",
    "DATA_FILE = \"library_usage.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f5c8d-ecca-4086-9794-68aaf6044152",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c80edc-7b8a-445f-8e06-ae6fdbf03aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables to track rate limit status\n",
    "remaining_requests = 3000  # Authenticated GitHub API limit (increased from 60)\n",
    "rate_limit_reset_time = 0\n",
    "last_rate_check = 0\n",
    "RATE_LIMIT_WAIT = True  # Set to False to exit instead of waiting for rate limit reset\n",
    "RETRY_DELAY = 1  # Reduced from 2\n",
    "\n",
    "def get_headers() -> Dict[str, str]:\n",
    "    \"\"\"Get headers for API requests with random user agent and authentication if available.\"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": random.choice(USER_AGENTS),\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    if GITHUB_TOKEN:\n",
    "        headers[\"Authorization\"] = f\"token {GITHUB_TOKEN}\"\n",
    "    return headers\n",
    "\n",
    "class RateLimitExceeded(Exception):\n",
    "    \"\"\"Exception raised when GitHub API rate limit is exceeded.\"\"\"\n",
    "    pass\n",
    "\n",
    "def check_rate_limit() -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Check GitHub API rate limit status.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (remaining requests, reset time in seconds)\n",
    "    \"\"\"\n",
    "    global remaining_requests, rate_limit_reset_time, last_rate_check\n",
    "    \n",
    "    # Only check every 30 seconds to avoid wasting requests (increased from 10)\n",
    "    current_time = time.time()\n",
    "    if current_time - last_rate_check < 30:\n",
    "        return remaining_requests, rate_limit_reset_time\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(f\"{GITHUB_API_URL}/rate_limit\", headers=get_headers())\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'resources' in data and 'core' in data['resources']:\n",
    "            remaining_requests = data['resources']['core']['remaining']\n",
    "            rate_limit_reset_time = data['resources']['core']['reset']\n",
    "            last_rate_check = current_time\n",
    "            \n",
    "            logging.info(f\"Rate limit status: {remaining_requests} requests remaining, \" +\n",
    "                        f\"resets in {rate_limit_reset_time - current_time:.1f} seconds\")\n",
    "            \n",
    "            return remaining_requests, rate_limit_reset_time\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Failed to check rate limit: {e}\")\n",
    "    \n",
    "    return remaining_requests, rate_limit_reset_time\n",
    "\n",
    "def wait_for_rate_limit() -> bool:\n",
    "    \"\"\"\n",
    "    Wait for rate limit to reset if needed.\n",
    "    \n",
    "    Returns:\n",
    "        True if we waited and rate limit should be reset, False if program should exit\n",
    "    \"\"\"\n",
    "    remaining, reset_time = check_rate_limit()\n",
    "    \n",
    "    # More aggressive approach - only wait when we have very few requests left\n",
    "    if remaining > 1:  # Reduced buffer from 5 to 1\n",
    "        return True\n",
    "    \n",
    "    wait_time = max(0, reset_time - time.time())\n",
    "    \n",
    "    if wait_time > 300 and not RATE_LIMIT_WAIT:  # More than 5 minutes wait\n",
    "        logging.error(f\"Rate limit exceeded. Would need to wait {wait_time/60:.1f} minutes. Exiting.\")\n",
    "        return False\n",
    "    \n",
    "    logging.warning(f\"Rate limit almost reached. Waiting {wait_time:.1f} seconds for reset...\")\n",
    "    \n",
    "    # Print countdown every 60 seconds (increased from 30)\n",
    "    while wait_time > 0:\n",
    "        time.sleep(min(60, wait_time))\n",
    "        wait_time = max(0, reset_time - time.time())\n",
    "        if wait_time > 0:\n",
    "            logging.info(f\"Still waiting for rate limit reset: {wait_time:.1f} seconds remaining\")\n",
    "    \n",
    "    # Reset our tracking variables\n",
    "    global remaining_requests, last_rate_check\n",
    "    remaining_requests = 5000  # Default authenticated GitHub API limit (increased from 60)\n",
    "    last_rate_check = 0\n",
    "    \n",
    "    logging.info(\"Rate limit should be reset now. Resuming operations.\")\n",
    "    return True\n",
    "\n",
    "def make_github_request(url: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Make a request to GitHub API with rate limit handling but no retries.\n",
    "    \n",
    "    Args:\n",
    "        url: The API URL to request\n",
    "        params: Optional query parameters\n",
    "        \n",
    "    Returns:\n",
    "        Parsed JSON response\n",
    "        \n",
    "    Raises:\n",
    "        RateLimitExceeded: If rate limit is hit and waiting is not possible\n",
    "        RequestException: For other request errors\n",
    "    \"\"\"\n",
    "    global remaining_requests, rate_limit_reset_time\n",
    "    \n",
    "    # Only check rate limit if we're getting close to the limit\n",
    "    if remaining_requests <= 100:  # Only check when getting low\n",
    "        if not wait_for_rate_limit():\n",
    "            raise RateLimitExceeded(\"Rate limit exceeded and waiting is disabled\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=get_headers(), params=params)\n",
    "        \n",
    "        # Update rate limit info from response headers\n",
    "        if 'X-RateLimit-Remaining' in response.headers:\n",
    "            remaining_requests = int(response.headers['X-RateLimit-Remaining'])\n",
    "            rate_limit_reset_time = int(response.headers['X-RateLimit-Reset'])\n",
    "        \n",
    "        # Handle rate limiting - no retry, just report the error\n",
    "        if response.status_code == 403 and remaining_requests == 0:\n",
    "            logging.error(\"Rate limit exceeded\")\n",
    "            raise RateLimitExceeded(\"Rate limit exceeded\")\n",
    "        \n",
    "        # Special handling for common error codes\n",
    "        if response.status_code == 404:\n",
    "            logging.warning(f\"Resource not found: {url}\")\n",
    "        elif response.status_code == 451:\n",
    "            logging.warning(f\"Resource unavailable for legal reasons (451): {url}\")\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        logging.warning(f\"HTTP error for {url}: {e}\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.warning(f\"JSON decode error for {url}: {e}\")\n",
    "        raise\n",
    "    except RequestException as e:\n",
    "        logging.warning(f\"Request error for {url}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd6ae4-55e2-41fe-802b-cb5af820aec0",
   "metadata": {},
   "source": [
    "### Get Random Python Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17c574e-471a-42e5-8291-f4c5bdc594b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_python_repos(n: int = 10, min_stars: int = 0, max_per_page: int = None) -> List[Tuple[str, str, str]]:\n",
    "    \"\"\"\n",
    "    Get random Python repositories from GitHub using the repositories endpoint with random IDs.\n",
    "    Uses the utility functions for rate limiting and request handling.\n",
    "    \n",
    "    Args:\n",
    "        n: Number of repositories to fetch\n",
    "        min_stars: Minimum number of stars for repositories\n",
    "        max_per_page: Maximum number of repositories to consider from each page (None = all)\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples (repo_name, repo_url, last_updated)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    while len(results) < n:\n",
    "        try:\n",
    "            # Generate a random repository ID in a reasonable range\n",
    "            random_id = random.randint(1, 700_000_000)\n",
    "            \n",
    "            # Fetch repositories starting from random ID\n",
    "            url = f\"{GITHUB_API_URL}/repositories?since={random_id}\"\n",
    "            \n",
    "            try:\n",
    "                response = make_github_request(url)\n",
    "                repos = response\n",
    "            except RateLimitExceeded:\n",
    "                logging.warning(\"Rate limit exceeded while fetching random repositories. Waiting...\")\n",
    "                if not wait_for_rate_limit():\n",
    "                    logging.error(\"Could not wait for rate limit reset. Exiting.\")\n",
    "                    break\n",
    "                continue\n",
    "            \n",
    "            # Limit number of repos to consider from this page if specified\n",
    "            if max_per_page:\n",
    "                repos = repos[:max_per_page]\n",
    "            \n",
    "            # Process each repository\n",
    "            for repo in repos:\n",
    "                # Get repository name\n",
    "                repo_name = repo.get(\"full_name\")\n",
    "                if not repo_name:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Check if it's a Python repository and meets star criteria\n",
    "                    repo_url = f\"{GITHUB_API_URL}/repos/{repo_name}\"\n",
    "                    repo_data = make_github_request(repo_url)\n",
    "                    \n",
    "                    # Check language and stars\n",
    "                    if (repo_data.get(\"language\") == \"Python\" and \n",
    "                            repo_data.get(\"stargazers_count\", 0) >= min_stars):\n",
    "                        \n",
    "                        results.append((\n",
    "                            repo_name,\n",
    "                            repo_data.get(\"html_url\", \"\"),\n",
    "                            repo_data.get(\"updated_at\", \"\")\n",
    "                        ))\n",
    "                        logging.info(f\"Found: {repo_name} (Stars: {repo_data.get('stargazers_count')})\")\n",
    "                        \n",
    "                        # Check if we have enough results\n",
    "                        if len(results) >= n:\n",
    "                            break\n",
    "                \n",
    "                except RateLimitExceeded:\n",
    "                    logging.warning(\"Rate limit exceeded while fetching repo details. Waiting...\")\n",
    "                    if not wait_for_rate_limit():\n",
    "                        logging.error(\"Could not wait for rate limit reset. Exiting.\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Error processing repository {repo_name}: {e}\")\n",
    "                    continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in repository fetch: {e}\")\n",
    "            # Exponential backoff on errors\n",
    "            time.sleep(10)\n",
    "    \n",
    "    logging.info(f\"Successfully collected {len(results)} random Python repositories\")\n",
    "    return results[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d9733-4aa7-4dde-abc3-c7f5c7f7746d",
   "metadata": {},
   "source": [
    "### Get Python Files and Analyze Files per Repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae23589-e0f7-4205-84cb-750983b40929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_branch(repo_name: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Get the default branch (main or master) for a repository.\n",
    "    Returns None if the branch cannot be determined.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not wait_for_rate_limit():\n",
    "            raise RateLimitExceeded(\"Rate limit exceeded while getting default branch\")\n",
    "            \n",
    "        response = make_github_request(f\"{GITHUB_API_URL}/repos/{repo_name}\")\n",
    "        default_branch = response.get(\"default_branch\", \"main\")\n",
    "        return default_branch\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Couldn't determine default branch for {repo_name}: {e}\")\n",
    "        # Return None to indicate we couldn't get the branch\n",
    "        return None\n",
    "\n",
    "def get_python_files(repo_name: str, max_files: int = 10, seed: int = 42) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of Python files in the repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_name: Full name of the repository (owner/repo)\n",
    "        max_files: Maximum number of files to return\n",
    "        seed: Random seed for reproducible file selection\n",
    "        \n",
    "    Returns:\n",
    "        List of file paths\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not wait_for_rate_limit():\n",
    "            raise RateLimitExceeded(\"Rate limit exceeded while getting Python files\")\n",
    "        \n",
    "        default_branch = get_default_branch(repo_name)\n",
    "        if default_branch is None:\n",
    "            logging.warning(f\"Skipping repo {repo_name} - couldn't determine default branch\")\n",
    "            return []\n",
    "            \n",
    "        url = f\"{GITHUB_API_URL}/repos/{repo_name}/git/trees/{default_branch}?recursive=1\"\n",
    "        \n",
    "        try:\n",
    "            response = make_github_request(url)\n",
    "            \n",
    "            if 'tree' in response:\n",
    "                python_files = [file['path'] for file in response['tree'] \n",
    "                        if file['path'].endswith('.py') and file['type'] == 'blob']\n",
    "                \n",
    "                # Set seed and shuffle to ensure reproducible file selection\n",
    "                random.seed(seed)\n",
    "                random.shuffle(python_files)\n",
    "                python_files = python_files[:max_files]\n",
    "                \n",
    "                return python_files\n",
    "        except RateLimitExceeded:\n",
    "            logging.warning(f\"Rate limit exceeded while getting files for {repo_name}\")\n",
    "            # Try fallback method\n",
    "        \n",
    "        # Fallback method: try to get files from the repo contents\n",
    "        url = f\"{GITHUB_API_URL}/repos/{repo_name}/contents\"\n",
    "        response = make_github_request(url)\n",
    "        \n",
    "        python_files = []\n",
    "        for item in response:\n",
    "            if item['type'] == 'file' and item['name'].endswith('.py'):\n",
    "                python_files.append(item['path'])\n",
    "            elif item['type'] == 'dir':\n",
    "                # Try to look in top-level directories\n",
    "                try:\n",
    "                    dir_url = f\"{GITHUB_API_URL}/repos/{repo_name}/contents/{item['path']}\"\n",
    "                    dir_response = make_github_request(dir_url)\n",
    "                    \n",
    "                    for dir_item in dir_response:\n",
    "                        if dir_item['type'] == 'file' and dir_item['name'].endswith('.py'):\n",
    "                            python_files.append(dir_item['path'])\n",
    "                except Exception:\n",
    "                    pass\n",
    "                    \n",
    "        # Set seed and shuffle files from fallback method as well\n",
    "        random.seed(seed)\n",
    "        random.shuffle(python_files)\n",
    "        python_files = python_files[:max_files]\n",
    "        \n",
    "        return python_files\n",
    "                \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error getting Python files for {repo_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_imports(file_content: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Extract all imported module names from Python code using the ast module.\n",
    "    \n",
    "    Args:\n",
    "        file_content: Python code content as a string\n",
    "        \n",
    "    Returns:\n",
    "        Set of top-level module names that are imported\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the code into an AST\n",
    "        tree = ast.parse(file_content)\n",
    "        \n",
    "        imports = set()\n",
    "        \n",
    "        # Walk through the AST nodes\n",
    "        for node in ast.walk(tree):\n",
    "            # Handle \"import module\" or \"import module.submodule\" statements\n",
    "            if isinstance(node, ast.Import):\n",
    "                for name in node.names:\n",
    "                    # Extract the top-level module name (before any dots)\n",
    "                    module_name = name.name.split('.', 1)[0]\n",
    "                    imports.add(module_name)\n",
    "            \n",
    "            # Handle \"from module import name\" statements\n",
    "            elif isinstance(node, ast.ImportFrom):\n",
    "                if node.module:  # In case of \"from . import name\"\n",
    "                    # Extract the top-level module name (before any dots)\n",
    "                    module_name = node.module.split('.', 1)[0]\n",
    "                    imports.add(module_name)\n",
    "        \n",
    "        return imports\n",
    "    \n",
    "    except SyntaxError:\n",
    "        # Fallback to regex for files with syntax errors\n",
    "        fallback_imports = set()\n",
    "        lines = file_content.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            # Match import statements\n",
    "            import_match = re.match(r'\\s*import\\s+([\\w\\s,]+)(?:\\s+as\\s+\\w+)?', line)\n",
    "            if import_match:\n",
    "                modules = import_match.group(1).split(',')\n",
    "                for module in modules:\n",
    "                    module_name = module.strip().split('.', 1)[0].split()[0]\n",
    "                    fallback_imports.add(module_name)\n",
    "                    \n",
    "            # Match from statements\n",
    "            from_match = re.match(r'\\s*from\\s+(\\w+)', line)\n",
    "            if from_match:\n",
    "                fallback_imports.add(from_match.group(1))\n",
    "                \n",
    "        return fallback_imports\n",
    "\n",
    "def extract_imports(content: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Extract imported libraries from Python content using AST parsing\n",
    "    and regex as a fallback for edge cases.\n",
    "    \"\"\"\n",
    "    libraries = set()\n",
    "    \n",
    "    # AST parsing for reliable import extraction\n",
    "    try:\n",
    "        tree = ast.parse(content)\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Import):\n",
    "                for name in node.names:\n",
    "                    libraries.add(name.name.split('.')[0])\n",
    "            elif isinstance(node, ast.ImportFrom):\n",
    "                if node.module:\n",
    "                    libraries.add(node.module.split('.')[0])\n",
    "    except SyntaxError:\n",
    "        # Fallback to regex for files with syntax errors\n",
    "        import_pattern = r'^import\\s+([\\w\\.]+)|^from\\s+([\\w\\.]+)\\s+import'\n",
    "        for match in re.finditer(import_pattern, content, re.MULTILINE):\n",
    "            lib = match.group(1) or match.group(2)\n",
    "            if lib:\n",
    "                libraries.add(lib.split('.')[0])\n",
    "                \n",
    "    return libraries\n",
    "\n",
    "def analyze_repo(repo_info: Tuple[str, str, str]) -> List[Tuple[str, str, str, str, str]]:\n",
    "    \"\"\"\n",
    "    Analyze a GitHub repository for Python library usage by cloning it once.\n",
    "    \n",
    "    Args:\n",
    "        repo_info: Tuple of (repo_name, repo_url, last_updated)\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples (library_name, repo_name, file_path, fetch_date, last_updated)\n",
    "    \"\"\"\n",
    "    repo_name, repo_url, last_updated = repo_info\n",
    "    logging.info(f\"Processing repo: {repo_name}\")\n",
    "    \n",
    "    repo_results = []\n",
    "    fetch_date = datetime.utcnow().isoformat()\n",
    "    \n",
    "    # Create a temporary directory for the cloned repo\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        try:\n",
    "            # Clone the repository with minimal depth\n",
    "            clone_cmd = f\"git clone --depth 1 https://github.com/{repo_name}.git {temp_dir}\"\n",
    "            subprocess.run(clone_cmd, shell=True, check=True, capture_output=True)\n",
    "            \n",
    "            # Find Python files in the repository\n",
    "            python_files = []\n",
    "            for root, _, files in os.walk(temp_dir):\n",
    "                for file in files:\n",
    "                    if file.endswith('.py'):\n",
    "                        relative_path = os.path.relpath(os.path.join(root, file), temp_dir)\n",
    "                        python_files.append(relative_path)\n",
    "                \n",
    "                # Limit the number of files to analyze if there are too many\n",
    "                if len(python_files) >= 10:\n",
    "                    python_files = python_files[:10]\n",
    "                    break\n",
    "            \n",
    "            # Process each Python file\n",
    "            for file_path in python_files:\n",
    "                try:\n",
    "                    full_path = os.path.join(temp_dir, file_path)\n",
    "                    with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    imports = extract_imports(content)\n",
    "                    \n",
    "                    for library in imports:\n",
    "                        repo_results.append((\n",
    "                            library, \n",
    "                            repo_name, \n",
    "                            file_path, \n",
    "                            fetch_date, \n",
    "                            last_updated\n",
    "                        ))\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Error processing file {file_path} in {repo_name}: {e}\")\n",
    "            \n",
    "            return repo_results\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to analyze repo {repo_name}: {e}\")\n",
    "            return []\n",
    "\n",
    "def save_results(results: List[Tuple[str, str, str, str, str, bool]]) -> None:\n",
    "    \"\"\"Save analysis results to CSV file with proper error handling.\"\"\"\n",
    "    if not results:\n",
    "        logging.warning(\"No results to save\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        file_exists = os.path.exists(DATA_FILE)\n",
    "        \n",
    "        with open(DATA_FILE, \"a\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if not file_exists:\n",
    "                writer.writerow([\n",
    "                    \"library_name\", \n",
    "                    \"repo\", \n",
    "                    \"file\", \n",
    "                    \"fetch_date\", \n",
    "                    \"last_updated\" \n",
    "                ])\n",
    "            writer.writerows(results)\n",
    "        \n",
    "        logging.info(f\"Saved {len(results)} entries to {DATA_FILE}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving results to CSV: {e}\")\n",
    "        \n",
    "        # Emergency backup\n",
    "        backup_file = f\"backup_results_{int(time.time())}.json\"\n",
    "        with open(backup_file, \"w\") as f:\n",
    "            json.dump(results, f)\n",
    "        logging.info(f\"Backup saved to {backup_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a9b4368-94ec-4b35-b7e8-e601cad5019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 20:12:35,226 - INFO - Fetching 50 repositories...\n",
      "2025-03-12 20:12:37,380 - WARNING - Resource not found: https://api.github.com/repos/awsassets/ipfs-crawler\n",
      "2025-03-12 20:12:37,382 - WARNING - HTTP error for https://api.github.com/repos/awsassets/ipfs-crawler: 404 Client Error: Not Found for url: https://api.github.com/repos/awsassets/ipfs-crawler\n",
      "2025-03-12 20:12:37,383 - WARNING - Error processing repository awsassets/ipfs-crawler: 404 Client Error: Not Found for url: https://api.github.com/repos/awsassets/ipfs-crawler\n",
      "2025-03-12 20:12:39,031 - INFO - Found: shafiurrahman/heroku-salary-prediction (Stars: 0)\n",
      "2025-03-12 20:12:39,470 - WARNING - HTTP error for https://api.github.com/repos/Gomes09/MagiskOnWSA: 403 Client Error: Forbidden for url: https://api.github.com/repos/Gomes09/MagiskOnWSA\n",
      "2025-03-12 20:12:39,470 - WARNING - Error processing repository Gomes09/MagiskOnWSA: 403 Client Error: Forbidden for url: https://api.github.com/repos/Gomes09/MagiskOnWSA\n",
      "2025-03-12 20:12:39,774 - INFO - Found: David-coder02/AirBnB_clone (Stars: 0)\n",
      "2025-03-12 20:12:46,384 - WARNING - HTTP error for https://api.github.com/repos/thegambid/MagiskOnWSA: 403 Client Error: Forbidden for url: https://api.github.com/repos/thegambid/MagiskOnWSA\n",
      "2025-03-12 20:12:46,386 - WARNING - Error processing repository thegambid/MagiskOnWSA: 403 Client Error: Forbidden for url: https://api.github.com/repos/thegambid/MagiskOnWSA\n",
      "2025-03-12 20:12:52,649 - INFO - Found: matt5797/rawsocket_sniffer (Stars: 0)\n",
      "2025-03-12 20:13:01,210 - WARNING - HTTP error for https://api.github.com/repos/A525-mine/MagiskOnWSA: 403 Client Error: Forbidden for url: https://api.github.com/repos/A525-mine/MagiskOnWSA\n",
      "2025-03-12 20:13:01,212 - WARNING - Error processing repository A525-mine/MagiskOnWSA: 403 Client Error: Forbidden for url: https://api.github.com/repos/A525-mine/MagiskOnWSA\n",
      "2025-03-12 20:13:01,950 - WARNING - HTTP error for https://api.github.com/repos/liuqiaochi/juejin-auto-checkin: 403 Client Error: Forbidden for url: https://api.github.com/repos/liuqiaochi/juejin-auto-checkin\n",
      "2025-03-12 20:13:01,951 - WARNING - Error processing repository liuqiaochi/juejin-auto-checkin: 403 Client Error: Forbidden for url: https://api.github.com/repos/liuqiaochi/juejin-auto-checkin\n",
      "2025-03-12 20:13:02,175 - WARNING - HTTP error for https://api.github.com/repos/shananwar/MagiskOnWSA: 403 Client Error: Forbidden for url: https://api.github.com/repos/shananwar/MagiskOnWSA\n",
      "2025-03-12 20:13:02,176 - WARNING - Error processing repository shananwar/MagiskOnWSA: 403 Client Error: Forbidden for url: https://api.github.com/repos/shananwar/MagiskOnWSA\n",
      "2025-03-12 20:13:07,092 - INFO - Found: Ocupe/Projectors (Stars: 210)\n",
      "2025-03-12 20:13:08,889 - WARNING - Resource not found: https://api.github.com/repos/paultrusedale1/Paultrusedale\n",
      "2025-03-12 20:13:08,890 - WARNING - HTTP error for https://api.github.com/repos/paultrusedale1/Paultrusedale: 404 Client Error: Not Found for url: https://api.github.com/repos/paultrusedale1/Paultrusedale\n",
      "2025-03-12 20:13:08,890 - WARNING - Error processing repository paultrusedale1/Paultrusedale: 404 Client Error: Not Found for url: https://api.github.com/repos/paultrusedale1/Paultrusedale\n",
      "2025-03-12 20:13:18,382 - INFO - Found: Hhacel/Python-Pong (Stars: 0)\n",
      "2025-03-12 20:13:19,129 - INFO - Found: rthorst/TwitterSentiment (Stars: 7)\n",
      "2025-03-12 20:13:19,399 - INFO - Found: ctberthiaume/seaflowpy (Stars: 0)\n",
      "2025-03-12 20:13:24,171 - INFO - Found: adm116/Scripts (Stars: 0)\n",
      "2025-03-12 20:13:33,206 - INFO - Found: shayanshakiba/tgcf (Stars: 0)\n",
      "2025-03-12 20:13:33,691 - INFO - Found: ghayward/the_Lord_always_delivers_functions (Stars: 1)\n",
      "2025-03-12 20:13:37,115 - INFO - Found: ingridaburto/tienda1 (Stars: 0)\n",
      "2025-03-12 20:13:39,143 - INFO - Found: mmiezianko/computational-intelligence-proj (Stars: 0)\n",
      "2025-03-12 20:13:39,667 - INFO - Found: santiagosimonsantos/UVa (Stars: 1)\n",
      "2025-03-12 20:13:40,640 - INFO - Found: Darkhunter9/EBSD_CNN_Public (Stars: 0)\n",
      "2025-03-12 20:13:44,269 - INFO - Found: iremharnak/community_characters (Stars: 0)\n",
      "2025-03-12 20:13:45,877 - INFO - Found: Anderton25/Gerador-de-Senha (Stars: 0)\n",
      "2025-03-12 20:13:46,246 - INFO - Found: Mitchellpkt/matrixprofile (Stars: 0)\n",
      "2025-03-12 20:13:54,817 - INFO - Found: FLAMINGxFURY/idtest (Stars: 0)\n",
      "2025-03-12 20:13:54,986 - WARNING - Resource not found: https://api.github.com/repos/denyo7/11324225\n",
      "2025-03-12 20:13:54,988 - WARNING - HTTP error for https://api.github.com/repos/denyo7/11324225: 404 Client Error: Not Found for url: https://api.github.com/repos/denyo7/11324225\n",
      "2025-03-12 20:13:54,989 - WARNING - Error processing repository denyo7/11324225: 404 Client Error: Not Found for url: https://api.github.com/repos/denyo7/11324225\n",
      "2025-03-12 20:13:57,077 - WARNING - Resource not found: https://api.github.com/repos/iAmSpace/spx-powercord-plugins\n",
      "2025-03-12 20:13:57,079 - WARNING - HTTP error for https://api.github.com/repos/iAmSpace/spx-powercord-plugins: 404 Client Error: Not Found for url: https://api.github.com/repos/iAmSpace/spx-powercord-plugins\n",
      "2025-03-12 20:13:57,080 - WARNING - Error processing repository iAmSpace/spx-powercord-plugins: 404 Client Error: Not Found for url: https://api.github.com/repos/iAmSpace/spx-powercord-plugins\n",
      "2025-03-12 20:13:57,831 - INFO - Found: rkania3/rahul-web-app (Stars: 0)\n",
      "2025-03-12 20:13:58,278 - WARNING - Resource not found: https://api.github.com/repos/Dark-FN/Stepnnn\n",
      "2025-03-12 20:13:58,278 - WARNING - HTTP error for https://api.github.com/repos/Dark-FN/Stepnnn: 404 Client Error: Not Found for url: https://api.github.com/repos/Dark-FN/Stepnnn\n",
      "2025-03-12 20:13:58,279 - WARNING - Error processing repository Dark-FN/Stepnnn: 404 Client Error: Not Found for url: https://api.github.com/repos/Dark-FN/Stepnnn\n",
      "2025-03-12 20:14:00,176 - INFO - Found: emltoja/wstep_do_informatyki_i_programowania (Stars: 0)\n",
      "2025-03-12 20:14:00,359 - WARNING - Resource not found: https://api.github.com/repos/SixShoot/lfstratdb-aion-api\n",
      "2025-03-12 20:14:00,362 - WARNING - HTTP error for https://api.github.com/repos/SixShoot/lfstratdb-aion-api: 404 Client Error: Not Found for url: https://api.github.com/repos/SixShoot/lfstratdb-aion-api\n",
      "2025-03-12 20:14:00,363 - WARNING - Error processing repository SixShoot/lfstratdb-aion-api: 404 Client Error: Not Found for url: https://api.github.com/repos/SixShoot/lfstratdb-aion-api\n",
      "2025-03-12 20:14:02,766 - WARNING - Resource not found: https://api.github.com/repos/Treatwinwin/legionnaire19086\n",
      "2025-03-12 20:14:02,769 - WARNING - HTTP error for https://api.github.com/repos/Treatwinwin/legionnaire19086: 404 Client Error: Not Found for url: https://api.github.com/repos/Treatwinwin/legionnaire19086\n",
      "2025-03-12 20:14:02,769 - WARNING - Error processing repository Treatwinwin/legionnaire19086: 404 Client Error: Not Found for url: https://api.github.com/repos/Treatwinwin/legionnaire19086\n",
      "2025-03-12 20:14:02,932 - WARNING - Resource not found: https://api.github.com/repos/belleeemaill/xxbelleeemaill\n",
      "2025-03-12 20:14:02,932 - WARNING - HTTP error for https://api.github.com/repos/belleeemaill/xxbelleeemaill: 404 Client Error: Not Found for url: https://api.github.com/repos/belleeemaill/xxbelleeemaill\n",
      "2025-03-12 20:14:02,933 - WARNING - Error processing repository belleeemaill/xxbelleeemaill: 404 Client Error: Not Found for url: https://api.github.com/repos/belleeemaill/xxbelleeemaill\n",
      "2025-03-12 20:14:05,326 - INFO - Found: TrellixVulnTeam/tecweb_ac04_9BBK (Stars: 0)\n",
      "2025-03-12 20:14:06,663 - WARNING - Resource not found: https://api.github.com/repos/Playiswindow/limbo\n",
      "2025-03-12 20:14:06,664 - WARNING - HTTP error for https://api.github.com/repos/Playiswindow/limbo: 404 Client Error: Not Found for url: https://api.github.com/repos/Playiswindow/limbo\n",
      "2025-03-12 20:14:06,665 - WARNING - Error processing repository Playiswindow/limbo: 404 Client Error: Not Found for url: https://api.github.com/repos/Playiswindow/limbo\n",
      "2025-03-12 20:14:07,156 - WARNING - Resource not found: https://api.github.com/repos/qq1935046755qr/9_12585\n",
      "2025-03-12 20:14:07,157 - WARNING - HTTP error for https://api.github.com/repos/qq1935046755qr/9_12585: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755qr/9_12585\n",
      "2025-03-12 20:14:07,157 - WARNING - Error processing repository qq1935046755qr/9_12585: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755qr/9_12585\n",
      "2025-03-12 20:14:08,045 - INFO - Found: chenke91/mysql-compare (Stars: 2)\n",
      "2025-03-12 20:14:11,789 - INFO - Found: sahernandezr/lab-data-vikings (Stars: 0)\n",
      "2025-03-12 20:14:14,994 - WARNING - Resource not found: https://api.github.com/repos/Treatwinwin/bulgiest28127\n",
      "2025-03-12 20:14:14,999 - WARNING - HTTP error for https://api.github.com/repos/Treatwinwin/bulgiest28127: 404 Client Error: Not Found for url: https://api.github.com/repos/Treatwinwin/bulgiest28127\n",
      "2025-03-12 20:14:15,000 - WARNING - Error processing repository Treatwinwin/bulgiest28127: 404 Client Error: Not Found for url: https://api.github.com/repos/Treatwinwin/bulgiest28127\n",
      "2025-03-12 20:14:20,306 - INFO - Found: husniddin123/list_indexing_homework (Stars: 0)\n",
      "2025-03-12 20:14:27,884 - INFO - Found: artunandac/Little-Edd-Assistant (Stars: 0)\n",
      "2025-03-12 20:14:28,695 - WARNING - Resource not found: https://api.github.com/repos/habiv/Mudjiba12\n",
      "2025-03-12 20:14:28,696 - WARNING - HTTP error for https://api.github.com/repos/habiv/Mudjiba12: 404 Client Error: Not Found for url: https://api.github.com/repos/habiv/Mudjiba12\n",
      "2025-03-12 20:14:28,696 - WARNING - Error processing repository habiv/Mudjiba12: 404 Client Error: Not Found for url: https://api.github.com/repos/habiv/Mudjiba12\n",
      "2025-03-12 20:14:32,448 - WARNING - Resource not found: https://api.github.com/repos/hsdhjvcsdj/hfjhdsd\n",
      "2025-03-12 20:14:32,449 - WARNING - HTTP error for https://api.github.com/repos/hsdhjvcsdj/hfjhdsd: 404 Client Error: Not Found for url: https://api.github.com/repos/hsdhjvcsdj/hfjhdsd\n",
      "2025-03-12 20:14:32,449 - WARNING - Error processing repository hsdhjvcsdj/hfjhdsd: 404 Client Error: Not Found for url: https://api.github.com/repos/hsdhjvcsdj/hfjhdsd\n",
      "2025-03-12 20:14:32,720 - INFO - Found: wakunezu/eyecatch_generator (Stars: 0)\n",
      "2025-03-12 20:14:33,874 - INFO - Found: mrprimle/EmoProject (Stars: 0)\n",
      "2025-03-12 20:14:34,956 - INFO - Found: leeshinyook/RectangleCropper (Stars: 10)\n",
      "2025-03-12 20:14:41,507 - INFO - Found: Aditya-Bhargav-dev/Ds-Algo (Stars: 1)\n",
      "2025-03-12 20:14:50,194 - WARNING - Resource not found: https://api.github.com/repos/dedik132/bnmbnm\n",
      "2025-03-12 20:14:50,219 - WARNING - HTTP error for https://api.github.com/repos/dedik132/bnmbnm: 404 Client Error: Not Found for url: https://api.github.com/repos/dedik132/bnmbnm\n",
      "2025-03-12 20:14:50,241 - WARNING - Error processing repository dedik132/bnmbnm: 404 Client Error: Not Found for url: https://api.github.com/repos/dedik132/bnmbnm\n",
      "2025-03-12 20:14:51,734 - WARNING - Resource not found: https://api.github.com/repos/nnm1/gldly\n",
      "2025-03-12 20:14:51,735 - WARNING - HTTP error for https://api.github.com/repos/nnm1/gldly: 404 Client Error: Not Found for url: https://api.github.com/repos/nnm1/gldly\n",
      "2025-03-12 20:14:51,736 - WARNING - Error processing repository nnm1/gldly: 404 Client Error: Not Found for url: https://api.github.com/repos/nnm1/gldly\n",
      "2025-03-12 20:14:55,085 - INFO - Found: tarekrahman3/Instagram_Hashtag_Analysis (Stars: 0)\n",
      "2025-03-12 20:14:58,219 - INFO - Found: PPatrickGU/Python-project-FlappyMM (Stars: 3)\n",
      "2025-03-12 20:15:02,294 - INFO - Found: 505177793/shiyanlou-code (Stars: 0)\n",
      "2025-03-12 20:15:05,560 - INFO - Found: NMO732/Projects (Stars: 0)\n",
      "2025-03-12 20:15:08,033 - WARNING - Resource not found: https://api.github.com/repos/mimseo/SEO-Tech-Pro-Mims-FL\n",
      "2025-03-12 20:15:08,034 - WARNING - HTTP error for https://api.github.com/repos/mimseo/SEO-Tech-Pro-Mims-FL: 404 Client Error: Not Found for url: https://api.github.com/repos/mimseo/SEO-Tech-Pro-Mims-FL\n",
      "2025-03-12 20:15:08,034 - WARNING - Error processing repository mimseo/SEO-Tech-Pro-Mims-FL: 404 Client Error: Not Found for url: https://api.github.com/repos/mimseo/SEO-Tech-Pro-Mims-FL\n",
      "2025-03-12 20:15:09,446 - INFO - Found: timolesterhuis/python-plantuml (Stars: 0)\n",
      "2025-03-12 20:15:26,470 - WARNING - Resource not found: https://api.github.com/repos/manipulet/newrepo-app\n",
      "2025-03-12 20:15:26,473 - WARNING - HTTP error for https://api.github.com/repos/manipulet/newrepo-app: 404 Client Error: Not Found for url: https://api.github.com/repos/manipulet/newrepo-app\n",
      "2025-03-12 20:15:26,476 - WARNING - Error processing repository manipulet/newrepo-app: 404 Client Error: Not Found for url: https://api.github.com/repos/manipulet/newrepo-app\n",
      "2025-03-12 20:15:30,781 - INFO - Found: findryDev/SQLitePython (Stars: 0)\n",
      "2025-03-12 20:15:35,289 - INFO - Found: R4V88/Simple-filmweb-app-in-Python (Stars: 0)\n",
      "2025-03-12 20:15:35,731 - WARNING - Resource not found: https://api.github.com/repos/blaquez/governance\n",
      "2025-03-12 20:15:35,733 - WARNING - HTTP error for https://api.github.com/repos/blaquez/governance: 404 Client Error: Not Found for url: https://api.github.com/repos/blaquez/governance\n",
      "2025-03-12 20:15:35,734 - WARNING - Error processing repository blaquez/governance: 404 Client Error: Not Found for url: https://api.github.com/repos/blaquez/governance\n",
      "2025-03-12 20:15:36,827 - INFO - Found: cloudfellows/stuxnet-worm (Stars: 4)\n",
      "2025-03-12 20:15:48,256 - INFO - Found: Salehbigdeli/raytracer (Stars: 1)\n",
      "2025-03-12 20:15:54,995 - INFO - Found: oi111/test_1 (Stars: 0)\n",
      "2025-03-12 20:15:57,520 - WARNING - Resource not found: https://api.github.com/repos/qq1935046755r/94_14554\n",
      "2025-03-12 20:15:57,522 - WARNING - HTTP error for https://api.github.com/repos/qq1935046755r/94_14554: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755r/94_14554\n",
      "2025-03-12 20:15:57,523 - WARNING - Error processing repository qq1935046755r/94_14554: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755r/94_14554\n",
      "2025-03-12 20:15:59,488 - INFO - Found: Edt12/Platform-Fighting-game-WIP (Stars: 0)\n",
      "2025-03-12 20:16:08,581 - WARNING - Resource not found: https://api.github.com/repos/qq1935046755w/56_9501\n",
      "2025-03-12 20:16:08,588 - WARNING - HTTP error for https://api.github.com/repos/qq1935046755w/56_9501: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755w/56_9501\n",
      "2025-03-12 20:16:08,589 - WARNING - Error processing repository qq1935046755w/56_9501: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755w/56_9501\n",
      "2025-03-12 20:16:09,356 - WARNING - Resource not found: https://api.github.com/repos/qq1935046755q/93_4307\n",
      "2025-03-12 20:16:09,357 - WARNING - HTTP error for https://api.github.com/repos/qq1935046755q/93_4307: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755q/93_4307\n",
      "2025-03-12 20:16:09,358 - WARNING - Error processing repository qq1935046755q/93_4307: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755q/93_4307\n",
      "2025-03-12 20:16:09,809 - WARNING - Resource not found: https://api.github.com/repos/qq1935046755r/88_14555\n",
      "2025-03-12 20:16:09,810 - WARNING - HTTP error for https://api.github.com/repos/qq1935046755r/88_14555: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755r/88_14555\n",
      "2025-03-12 20:16:09,810 - WARNING - Error processing repository qq1935046755r/88_14555: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755r/88_14555\n",
      "2025-03-12 20:16:10,887 - WARNING - Resource not found: https://api.github.com/repos/qq1935046755t/74_19615\n",
      "2025-03-12 20:16:10,888 - WARNING - HTTP error for https://api.github.com/repos/qq1935046755t/74_19615: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755t/74_19615\n",
      "2025-03-12 20:16:10,889 - WARNING - Error processing repository qq1935046755t/74_19615: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755t/74_19615\n",
      "2025-03-12 20:16:12,039 - INFO - Found: aishAgarwal04/Python-Binary-Search-2 (Stars: 0)\n",
      "2025-03-12 20:16:12,529 - INFO - Found: PawQualityProducts/HeifER (Stars: 1)\n",
      "2025-03-12 20:16:15,497 - INFO - Found: PRATIK-BOTHRA/c142 (Stars: 0)\n",
      "2025-03-12 20:16:18,000 - INFO - Found: DavideRebuffo/compiti_vacanze (Stars: 0)\n",
      "2025-03-12 20:16:18,179 - WARNING - Resource not found: https://api.github.com/repos/qq1935046755q/32_4308\n",
      "2025-03-12 20:16:18,179 - WARNING - HTTP error for https://api.github.com/repos/qq1935046755q/32_4308: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755q/32_4308\n",
      "2025-03-12 20:16:18,180 - WARNING - Error processing repository qq1935046755q/32_4308: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755q/32_4308\n",
      "2025-03-12 20:16:18,758 - INFO - Found: sskyu1/djangogram (Stars: 0)\n",
      "2025-03-12 20:16:18,944 - WARNING - Resource not found: https://api.github.com/repos/qq1935046755r/56_14556\n",
      "2025-03-12 20:16:18,944 - WARNING - HTTP error for https://api.github.com/repos/qq1935046755r/56_14556: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755r/56_14556\n",
      "2025-03-12 20:16:18,945 - WARNING - Error processing repository qq1935046755r/56_14556: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755r/56_14556\n",
      "2025-03-12 20:16:19,148 - WARNING - Resource not found: https://api.github.com/repos/qq1935046755w/16_9502\n",
      "2025-03-12 20:16:19,149 - WARNING - HTTP error for https://api.github.com/repos/qq1935046755w/16_9502: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755w/16_9502\n",
      "2025-03-12 20:16:19,149 - WARNING - Error processing repository qq1935046755w/16_9502: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755w/16_9502\n",
      "2025-03-12 20:16:19,628 - WARNING - Resource not found: https://api.github.com/repos/qq1935046755t/14_19616\n",
      "2025-03-12 20:16:19,629 - WARNING - HTTP error for https://api.github.com/repos/qq1935046755t/14_19616: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755t/14_19616\n",
      "2025-03-12 20:16:19,630 - WARNING - Error processing repository qq1935046755t/14_19616: 404 Client Error: Not Found for url: https://api.github.com/repos/qq1935046755t/14_19616\n",
      "2025-03-12 20:16:20,354 - WARNING - Resource not found: https://api.github.com/repos/bring1232/po\n",
      "2025-03-12 20:16:20,355 - WARNING - HTTP error for https://api.github.com/repos/bring1232/po: 404 Client Error: Not Found for url: https://api.github.com/repos/bring1232/po\n",
      "2025-03-12 20:16:20,355 - WARNING - Error processing repository bring1232/po: 404 Client Error: Not Found for url: https://api.github.com/repos/bring1232/po\n",
      "2025-03-12 20:16:26,755 - INFO - Found: jsfenfen/irs_527 (Stars: 2)\n",
      "2025-03-12 20:16:27,603 - INFO - Found: Furkan9268/turtlebot_create (Stars: 0)\n",
      "2025-03-12 20:16:34,835 - INFO - Found: dz0ny/gp.recipe.node (Stars: 0)\n",
      "2025-03-12 20:16:36,612 - INFO - Found: MeGaPk/makerbot-gen5-api (Stars: 0)\n",
      "2025-03-12 20:16:38,682 - INFO - Found: leafiy/sublime-less2css (Stars: 0)\n",
      "2025-03-12 20:16:38,684 - INFO - Successfully collected 50 random Python repositories\n",
      "2025-03-12 20:16:38,687 - INFO - Fetched 50 repositories for analysis\n",
      "2025-03-12 20:16:38,694 - INFO - Created new CSV file: library_usage.csv\n",
      "Processing Repositories:   0%|                         | 0/50 [00:00<?, ?repo/s]2025-03-12 20:16:38,962 - INFO - Processing repo: shafiurrahman/heroku-salary-prediction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shafiurrahman/heroku-salary-prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:   2%|▎                | 1/50 [00:01<01:26,  1.76s/repo]2025-03-12 20:16:40,754 - INFO - Processing repo: David-coder02/AirBnB_clone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed shafiurrahman/heroku-salary-prediction: saved 7 library imports (total: 7)\n",
      "Processing David-coder02/AirBnB_clone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:   4%|▋                | 2/50 [00:02<01:04,  1.34s/repo]2025-03-12 20:16:41,762 - INFO - Processing repo: matt5797/rawsocket_sniffer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed David-coder02/AirBnB_clone: saved 12 library imports (total: 19)\n",
      "Processing matt5797/rawsocket_sniffer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:   6%|█                | 3/50 [00:03<00:52,  1.11s/repo]2025-03-12 20:16:42,592 - INFO - Processing repo: Ocupe/Projectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed matt5797/rawsocket_sniffer: saved 15 library imports (total: 34)\n",
      "Processing Ocupe/Projectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:   8%|█▎               | 4/50 [00:04<00:46,  1.00s/repo]2025-03-12 20:16:43,432 - INFO - Processing repo: Hhacel/Python-Pong\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Ocupe/Projectors: saved 25 library imports (total: 59)\n",
      "Processing Hhacel/Python-Pong...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  10%|█▋               | 5/50 [00:05<00:40,  1.12repo/s]2025-03-12 20:16:44,124 - INFO - Processing repo: rthorst/TwitterSentiment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Hhacel/Python-Pong: saved 9 library imports (total: 68)\n",
      "Processing rthorst/TwitterSentiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  12%|██               | 6/50 [00:08<01:16,  1.74s/repo]2025-03-12 20:16:47,505 - INFO - Processing repo: ctberthiaume/seaflowpy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed rthorst/TwitterSentiment: saved 79 library imports (total: 147)\n",
      "Processing ctberthiaume/seaflowpy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  14%|██▍              | 7/50 [00:09<01:02,  1.46s/repo]2025-03-12 20:16:48,402 - INFO - Processing repo: adm116/Scripts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed ctberthiaume/seaflowpy: saved 44 library imports (total: 191)\n",
      "Processing adm116/Scripts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  16%|██▋              | 8/50 [00:10<00:51,  1.23s/repo]2025-03-12 20:16:49,142 - INFO - Processing repo: shayanshakiba/tgcf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed adm116/Scripts: saved 1 library imports (total: 192)\n",
      "Processing shayanshakiba/tgcf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  18%|███              | 9/50 [00:11<00:46,  1.13s/repo]2025-03-12 20:16:50,032 - INFO - Processing repo: ghayward/the_Lord_always_delivers_functions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed shayanshakiba/tgcf: saved 45 library imports (total: 237)\n",
      "Processing ghayward/the_Lord_always_delivers_functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  20%|███▏            | 10/50 [00:11<00:39,  1.02repo/s]2025-03-12 20:16:50,704 - INFO - Processing repo: ingridaburto/tienda1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed ghayward/the_Lord_always_delivers_functions: no library imports found\n",
      "Processing ingridaburto/tienda1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  22%|███▌            | 11/50 [00:12<00:35,  1.08repo/s]2025-03-12 20:16:51,485 - INFO - Processing repo: mmiezianko/computational-intelligence-proj\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed ingridaburto/tienda1: saved 15 library imports (total: 252)\n",
      "Processing mmiezianko/computational-intelligence-proj...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  24%|███▊            | 12/50 [00:13<00:31,  1.20repo/s]2025-03-12 20:16:52,118 - INFO - Processing repo: santiagosimonsantos/UVa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mmiezianko/computational-intelligence-proj: saved 58 library imports (total: 310)\n",
      "Processing santiagosimonsantos/UVa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  26%|████▏           | 13/50 [00:13<00:30,  1.23repo/s]2025-03-12 20:16:52,887 - INFO - Processing repo: Darkhunter9/EBSD_CNN_Public\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed santiagosimonsantos/UVa: saved 7 library imports (total: 317)\n",
      "Processing Darkhunter9/EBSD_CNN_Public...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  28%|████▍           | 14/50 [00:14<00:27,  1.30repo/s]2025-03-12 20:16:53,549 - INFO - Processing repo: iremharnak/community_characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Darkhunter9/EBSD_CNN_Public: saved 64 library imports (total: 381)\n",
      "Processing iremharnak/community_characters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  30%|████▊           | 15/50 [00:15<00:25,  1.35repo/s]2025-03-12 20:16:54,231 - INFO - Processing repo: Anderton25/Gerador-de-Senha\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed iremharnak/community_characters: saved 13 library imports (total: 394)\n",
      "Processing Anderton25/Gerador-de-Senha...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  32%|█████           | 16/50 [00:15<00:24,  1.40repo/s]2025-03-12 20:16:54,876 - INFO - Processing repo: Mitchellpkt/matrixprofile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Anderton25/Gerador-de-Senha: saved 1 library imports (total: 395)\n",
      "Processing Mitchellpkt/matrixprofile...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  34%|█████▍          | 17/50 [00:16<00:26,  1.26repo/s]2025-03-12 20:16:55,850 - INFO - Processing repo: FLAMINGxFURY/idtest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Mitchellpkt/matrixprofile: saved 33 library imports (total: 428)\n",
      "Processing FLAMINGxFURY/idtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  36%|█████▊          | 18/50 [00:17<00:23,  1.36repo/s]2025-03-12 20:16:56,455 - INFO - Processing repo: rkania3/rahul-web-app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed FLAMINGxFURY/idtest: saved 2 library imports (total: 430)\n",
      "Processing rkania3/rahul-web-app...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  38%|██████          | 19/50 [00:18<00:21,  1.45repo/s]2025-03-12 20:16:57,038 - INFO - Processing repo: emltoja/wstep_do_informatyki_i_programowania\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed rkania3/rahul-web-app: saved 3 library imports (total: 433)\n",
      "Processing emltoja/wstep_do_informatyki_i_programowania...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  40%|██████▍         | 20/50 [00:18<00:20,  1.50repo/s]2025-03-12 20:16:57,651 - INFO - Processing repo: TrellixVulnTeam/tecweb_ac04_9BBK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed emltoja/wstep_do_informatyki_i_programowania: saved 16 library imports (total: 449)\n",
      "Processing TrellixVulnTeam/tecweb_ac04_9BBK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  42%|██████▋         | 21/50 [00:20<00:24,  1.16repo/s]2025-03-12 20:16:58,965 - INFO - Processing repo: chenke91/mysql-compare\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed TrellixVulnTeam/tecweb_ac04_9BBK: saved 9 library imports (total: 458)\n",
      "Processing chenke91/mysql-compare...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  44%|███████         | 22/50 [00:20<00:22,  1.26repo/s]2025-03-12 20:16:59,606 - INFO - Processing repo: sahernandezr/lab-data-vikings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed chenke91/mysql-compare: saved 3 library imports (total: 461)\n",
      "Processing sahernandezr/lab-data-vikings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  46%|███████▎        | 23/50 [00:21<00:20,  1.35repo/s]2025-03-12 20:17:00,225 - INFO - Processing repo: husniddin123/list_indexing_homework\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed sahernandezr/lab-data-vikings: saved 12 library imports (total: 473)\n",
      "Processing husniddin123/list_indexing_homework...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  48%|███████▋        | 24/50 [00:21<00:18,  1.41repo/s]2025-03-12 20:17:00,852 - INFO - Processing repo: artunandac/Little-Edd-Assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed husniddin123/list_indexing_homework: saved 1 library imports (total: 474)\n",
      "Processing artunandac/Little-Edd-Assistant...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  50%|████████        | 25/50 [00:22<00:16,  1.52repo/s]2025-03-12 20:17:01,389 - INFO - Processing repo: wakunezu/eyecatch_generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed artunandac/Little-Edd-Assistant: saved 9 library imports (total: 483)\n",
      "Processing wakunezu/eyecatch_generator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  52%|████████▎       | 26/50 [00:24<00:23,  1.03repo/s]2025-03-12 20:17:03,093 - INFO - Processing repo: mrprimle/EmoProject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed wakunezu/eyecatch_generator: saved 3 library imports (total: 486)\n",
      "Processing mrprimle/EmoProject...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  54%|████████▋       | 27/50 [00:29<00:51,  2.24s/repo]2025-03-12 20:17:08,296 - INFO - Processing repo: leeshinyook/RectangleCropper\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mrprimle/EmoProject: saved 7 library imports (total: 493)\n",
      "Processing leeshinyook/RectangleCropper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  56%|████████▉       | 28/50 [00:30<00:42,  1.94s/repo]2025-03-12 20:17:09,531 - INFO - Processing repo: Aditya-Bhargav-dev/Ds-Algo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed leeshinyook/RectangleCropper: saved 5 library imports (total: 498)\n",
      "Processing Aditya-Bhargav-dev/Ds-Algo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  58%|█████████▎      | 29/50 [00:31<00:32,  1.54s/repo]2025-03-12 20:17:10,144 - INFO - Processing repo: tarekrahman3/Instagram_Hashtag_Analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Aditya-Bhargav-dev/Ds-Algo: saved 4 library imports (total: 502)\n",
      "Processing tarekrahman3/Instagram_Hashtag_Analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  60%|█████████▌      | 30/50 [00:31<00:25,  1.28s/repo]2025-03-12 20:17:10,826 - INFO - Processing repo: PPatrickGU/Python-project-FlappyMM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed tarekrahman3/Instagram_Hashtag_Analysis: saved 9 library imports (total: 511)\n",
      "Processing PPatrickGU/Python-project-FlappyMM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  62%|█████████▉      | 31/50 [00:33<00:23,  1.24s/repo]2025-03-12 20:17:11,964 - INFO - Processing repo: 505177793/shiyanlou-code\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed PPatrickGU/Python-project-FlappyMM: saved 3 library imports (total: 514)\n",
      "Processing 505177793/shiyanlou-code...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  64%|██████████▏     | 32/50 [00:33<00:18,  1.05s/repo]2025-03-12 20:17:12,571 - INFO - Processing repo: NMO732/Projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 505177793/shiyanlou-code: no library imports found\n",
      "Processing NMO732/Projects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  66%|██████████▌     | 33/50 [00:34<00:15,  1.10repo/s]2025-03-12 20:17:13,160 - INFO - Processing repo: timolesterhuis/python-plantuml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed NMO732/Projects: saved 14 library imports (total: 528)\n",
      "Processing timolesterhuis/python-plantuml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  68%|██████████▉     | 34/50 [00:35<00:14,  1.14repo/s]2025-03-12 20:17:13,964 - INFO - Processing repo: findryDev/SQLitePython\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed timolesterhuis/python-plantuml: saved 16 library imports (total: 544)\n",
      "Processing findryDev/SQLitePython...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  70%|███████████▏    | 35/50 [00:35<00:12,  1.22repo/s]2025-03-12 20:17:14,643 - INFO - Processing repo: R4V88/Simple-filmweb-app-in-Python\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed findryDev/SQLitePython: saved 3 library imports (total: 547)\n",
      "Processing R4V88/Simple-filmweb-app-in-Python...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  72%|███████████▌    | 36/50 [00:39<00:25,  1.81s/repo]2025-03-12 20:17:18,758 - INFO - Processing repo: cloudfellows/stuxnet-worm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed R4V88/Simple-filmweb-app-in-Python: saved 16 library imports (total: 563)\n",
      "Processing cloudfellows/stuxnet-worm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  74%|███████████▊    | 37/50 [00:41<00:24,  1.87s/repo]2025-03-12 20:17:20,779 - INFO - Processing repo: Salehbigdeli/raytracer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed cloudfellows/stuxnet-worm: saved 40 library imports (total: 603)\n",
      "Processing Salehbigdeli/raytracer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  76%|████████████▏   | 38/50 [00:42<00:18,  1.53s/repo]2025-03-12 20:17:21,500 - INFO - Processing repo: oi111/test_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Salehbigdeli/raytracer: saved 3 library imports (total: 606)\n",
      "Processing oi111/test_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  78%|████████████▍   | 39/50 [00:45<00:20,  1.84s/repo]2025-03-12 20:17:24,069 - INFO - Processing repo: Edt12/Platform-Fighting-game-WIP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed oi111/test_1: saved 28 library imports (total: 634)\n",
      "Processing Edt12/Platform-Fighting-game-WIP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  80%|████████████▊   | 40/50 [00:45<00:14,  1.49s/repo]2025-03-12 20:17:24,747 - INFO - Processing repo: aishAgarwal04/Python-Binary-Search-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Edt12/Platform-Fighting-game-WIP: saved 4 library imports (total: 638)\n",
      "Processing aishAgarwal04/Python-Binary-Search-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  82%|█████████████   | 41/50 [00:46<00:11,  1.23s/repo]2025-03-12 20:17:25,361 - INFO - Processing repo: PawQualityProducts/HeifER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed aishAgarwal04/Python-Binary-Search-2: no library imports found\n",
      "Processing PawQualityProducts/HeifER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 20:17:27,775 - WARNING - Error processing file Prototype/venv/lib/python3.9/shutil.py in PawQualityProducts/HeifER: [Errno 2] No such file or directory: '/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/tmpqehvtpc0/Prototype/venv/lib/python3.9/shutil.py'\n",
      "2025-03-12 20:17:27,777 - WARNING - Error processing file Prototype/venv/lib/python3.9/tempfile.py in PawQualityProducts/HeifER: [Errno 2] No such file or directory: '/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/tmpqehvtpc0/Prototype/venv/lib/python3.9/tempfile.py'\n",
      "2025-03-12 20:17:27,777 - WARNING - Error processing file Prototype/venv/lib/python3.9/copyreg.py in PawQualityProducts/HeifER: [Errno 2] No such file or directory: '/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/tmpqehvtpc0/Prototype/venv/lib/python3.9/copyreg.py'\n",
      "2025-03-12 20:17:27,777 - WARNING - Error processing file Prototype/venv/lib/python3.9/rlcompleter.py in PawQualityProducts/HeifER: [Errno 2] No such file or directory: '/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/tmpqehvtpc0/Prototype/venv/lib/python3.9/rlcompleter.py'\n",
      "2025-03-12 20:17:27,778 - WARNING - Error processing file Prototype/venv/lib/python3.9/token.py in PawQualityProducts/HeifER: [Errno 2] No such file or directory: '/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/tmpqehvtpc0/Prototype/venv/lib/python3.9/token.py'\n",
      "2025-03-12 20:17:27,778 - WARNING - Error processing file Prototype/venv/lib/python3.9/base64.py in PawQualityProducts/HeifER: [Errno 2] No such file or directory: '/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/tmpqehvtpc0/Prototype/venv/lib/python3.9/base64.py'\n",
      "2025-03-12 20:17:27,778 - WARNING - Error processing file Prototype/venv/lib/python3.9/sre_constants.py in PawQualityProducts/HeifER: [Errno 2] No such file or directory: '/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/tmpqehvtpc0/Prototype/venv/lib/python3.9/sre_constants.py'\n",
      "2025-03-12 20:17:27,779 - WARNING - Error processing file Prototype/venv/lib/python3.9/weakref.py in PawQualityProducts/HeifER: [Errno 2] No such file or directory: '/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/tmpqehvtpc0/Prototype/venv/lib/python3.9/weakref.py'\n",
      "2025-03-12 20:17:27,779 - WARNING - Error processing file Prototype/venv/lib/python3.9/bisect.py in PawQualityProducts/HeifER: [Errno 2] No such file or directory: '/var/folders/2p/6m62flgx7677h842nfsgzgvh0000gn/T/tmpqehvtpc0/Prototype/venv/lib/python3.9/bisect.py'\n",
      "Processing Repositories:  84%|█████████████▍  | 42/50 [00:48<00:12,  1.62s/repo]2025-03-12 20:17:27,897 - INFO - Processing repo: PRATIK-BOTHRA/c142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed PawQualityProducts/HeifER: saved 3 library imports (total: 641)\n",
      "Processing PRATIK-BOTHRA/c142...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  86%|█████████████▊  | 43/50 [00:49<00:09,  1.36s/repo]2025-03-12 20:17:28,644 - INFO - Processing repo: DavideRebuffo/compiti_vacanze\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed PRATIK-BOTHRA/c142: saved 7 library imports (total: 648)\n",
      "Processing DavideRebuffo/compiti_vacanze...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  88%|██████████████  | 44/50 [00:50<00:06,  1.17s/repo]2025-03-12 20:17:29,363 - INFO - Processing repo: sskyu1/djangogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed DavideRebuffo/compiti_vacanze: saved 2 library imports (total: 650)\n",
      "Processing sskyu1/djangogram...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  90%|██████████████▍ | 45/50 [00:51<00:05,  1.02s/repo]2025-03-12 20:17:30,039 - INFO - Processing repo: jsfenfen/irs_527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed sskyu1/djangogram: saved 18 library imports (total: 668)\n",
      "Processing jsfenfen/irs_527...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  92%|██████████████▋ | 46/50 [00:51<00:03,  1.11repo/s]2025-03-12 20:17:30,659 - INFO - Processing repo: Furkan9268/turtlebot_create\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed jsfenfen/irs_527: saved 9 library imports (total: 677)\n",
      "Processing Furkan9268/turtlebot_create...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  94%|███████████████ | 47/50 [00:52<00:02,  1.15repo/s]2025-03-12 20:17:31,450 - INFO - Processing repo: dz0ny/gp.recipe.node\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Furkan9268/turtlebot_create: saved 49 library imports (total: 726)\n",
      "Processing dz0ny/gp.recipe.node...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  96%|███████████████▎| 48/50 [00:53<00:01,  1.24repo/s]2025-03-12 20:17:32,114 - INFO - Processing repo: MeGaPk/makerbot-gen5-api\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed dz0ny/gp.recipe.node: saved 39 library imports (total: 765)\n",
      "Processing MeGaPk/makerbot-gen5-api...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories:  98%|███████████████▋| 49/50 [00:53<00:00,  1.32repo/s]2025-03-12 20:17:32,750 - INFO - Processing repo: leafiy/sublime-less2css\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed MeGaPk/makerbot-gen5-api: saved 43 library imports (total: 808)\n",
      "Processing leafiy/sublime-less2css...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Repositories: 100%|████████████████| 50/50 [00:54<00:00,  1.09s/repo]\n",
      "2025-03-12 20:17:33,544 - INFO - Analysis complete. Analyzed 824 library imports across 50 repositories\n",
      "2025-03-12 20:17:33,544 - INFO - Results saved to library_usage.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed leafiy/sublime-less2css: saved 16 library imports (total: 824)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     62\u001b[0m     exit_code \u001b[38;5;241m=\u001b[39m main()\n\u001b[0;32m---> 63\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241m.\u001b[39mexit(exit_code)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to orchestrate the GitHub repository analysis.\"\"\"\n",
    "    try:\n",
    "        num_repos = 50  # Adjust as needed\n",
    "        logging.info(f\"Fetching {num_repos} repositories...\")\n",
    "        sampled_repos = get_random_python_repos(n=num_repos, min_stars=0)\n",
    "        logging.info(f\"Fetched {len(sampled_repos)} repositories for analysis\")\n",
    "        \n",
    "        # Create/initialize the CSV file before processing\n",
    "        file_exists = os.path.exists(DATA_FILE)\n",
    "        if not file_exists:\n",
    "            with open(DATA_FILE, \"w\", newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\n",
    "                    \"library_name\", \n",
    "                    \"repo\", \n",
    "                    \"file\", \n",
    "                    \"fetch_date\", \n",
    "                    \"last_updated\" \n",
    "                ])\n",
    "            logging.info(f\"Created new CSV file: {DATA_FILE}\")\n",
    "        \n",
    "        total_imports = 0\n",
    "        \n",
    "        # Process repositories sequentially with progress bar\n",
    "        for repo in tqdm(sampled_repos, desc=\"Processing Repositories\", unit=\"repo\"):\n",
    "            try:\n",
    "                repo_name = repo[0]\n",
    "                tqdm.write(f\"Processing {repo_name}...\")\n",
    "                \n",
    "                repo_results = analyze_repo(repo)\n",
    "                \n",
    "                # Write results to CSV immediately after each repo\n",
    "                if repo_results:\n",
    "                    with open(DATA_FILE, \"a\", newline='') as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerows(repo_results)\n",
    "                    \n",
    "                    total_imports += len(repo_results)\n",
    "                    tqdm.write(f\"Completed {repo_name}: saved {len(repo_results)} library imports (total: {total_imports})\")\n",
    "                else:\n",
    "                    tqdm.write(f\"Completed {repo_name}: no library imports found\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"Error processing {repo[0]}: {e}\")\n",
    "                error_file = f\"error_{repo[0].replace('/', '_')}_{int(time.time())}.txt\"\n",
    "                with open(error_file, \"w\") as f:\n",
    "                    f.write(f\"Error processing {repo[0]}: {str(e)}\\n\")\n",
    "                    f.write(traceback.format_exc())\n",
    "        \n",
    "        logging.info(f\"Analysis complete. Analyzed {total_imports} library imports across {len(sampled_repos)} repositories\")\n",
    "        logging.info(f\"Results saved to {DATA_FILE}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Fatal error in main process: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)\n",
    "        \n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exit_code = main()\n",
    "    sys.exit(exit_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbd84a-c421-4995-88bc-504385707f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Data Science)",
   "language": "python",
   "name": "py311ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
